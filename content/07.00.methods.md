## Methods {#sec:methods}

<!--
ERROR: the paragraph below could not be revised with the AI model due to the following error:

Request failed due to server shutdown {
  "error": {
    "message": "Request failed due to server shutdown",
    "type": "server_error",
    "param": null,
    "code": null
  }
}
 500 {'error': {'message': 'Request failed due to server shutdown', 'type': 'server_error', 'param': None, 'code': None}} {'Date': 'Tue, 19 Mar 2024 17:04:28 GMT', 'Content-Type': 'application/json', 'Content-Length': '141', 'Connection': 'keep-alive', 'access-control-allow-origin': '*', 'openai-model': 'gpt-4-0125-preview', 'openai-organization': 'university-of-pennsylvania-201', 'openai-processing-ms': '35743', 'openai-version': '2020-10-01', 'strict-transport-security': 'max-age=15724800; includeSubDomains', 'x-ratelimit-limit-requests': '500', 'x-ratelimit-limit-tokens': '450000', 'x-ratelimit-remaining-requests': '499', 'x-ratelimit-remaining-tokens': '449240', 'x-ratelimit-reset-requests': '120ms', 'x-ratelimit-reset-tokens': '101ms', 'x-request-id': 'req_9151a4c7a05777d6f3c665b091f81181', 'CF-Cache-Status': 'DYNAMIC', 'Server': 'cloudflare', 'CF-RAY': '866f09d4dfa85a33-IAD', 'alt-svc': 'h3=":443"; ma=86400'}
-->
PhenoPLIER is a framework that combines different computational approaches to integrate gene-trait associations and drug-induced transcriptional responses with groups of functionally-related genes (referred to as gene modules or latent variables/LVs).
Gene-trait associations are computed using the PrediXcan family of methods, whereas latent variables are inferred by the MultiPLIER models applied on large gene expression compendia.
PhenoPLIER provides 1) a regression model to compute an LV-trait association, 2) a consensus clustering approach applied to the latent space to learn shared and distinct transcriptomic properties between traits, and 3) an interpretable, LV-based drug repurposing framework.
We provide the details of these methods below.



### The PrediXcan family of methods for gene-based associations {#sec:methods:predixcan}

In our analysis, we employed the gene-based statistical methodologies known as Summary-PrediXcan (S-PrediXcan) [@doi:10.1038/s41467-018-03621-1] and Summary-MultiXcan (S-MultiXcan) [@doi:10.1371/journal.pgen.1007889], which are integral components of the PrediXcan family of methods [@doi:10.1038/ng.3367].
Collectively, these approaches are referred to under the umbrella term of transcription-wide association studies (TWAS).
Specifically, S-PrediXcan, the summary-based variant of PrediXcan, is designed to calculate the univariate association between a given trait and the predicted expression of a gene within a single tissue.
On the other hand, S-MultiXcan, which is the summary-based extension of MultiXcan, is utilized to ascertain the joint association between the predicted expression of a gene across all tissues and a specific trait.
A notable advantage of both S-PrediXcan and S-MultiXcan is their reliance solely on GWAS summary statistics, obviating the need for individual-level genotype and phenotype data.

In this section, we elucidate the Transcriptome-Wide Association Study (TWAS) methodologies that are essential for understanding our regression framework, as detailed in subsequent sections (for comprehensive details, refer to the cited literature).
We denote $\mathbf{y}$ as a vector representing the traits of $n$ individuals, which is centered to obviate the need for an intercept in our analyses.
The predicted gene expression for all individuals in tissue $l$ is given by $\tilde{\mathbf{t}}_l = \sum_{a \in \mathrm{model}_l} w_{a}^{l} X_{a}$, where $X_a$ represents the genotype of Single Nucleotide Polymorphism (SNP) $a$, and $w_{a}^{l}$ is the corresponding weight of SNP $a$ in the tissue-specific prediction model $l$.
The standardized expression $\mathbf{t}_l$ is derived from $\tilde{\mathbf{t}}_l$ and is normalized to have a mean of zero and a standard deviation of one.

$$
\tilde{\mathbf{t}}_l = \sum_{a \in \mathrm{model}_l} w_{a}^{l} X_{a}
$$

Here, $\tilde{\mathbf{t}}_l$ represents the gene's predicted expression level for a given tissue $l$, summed over all SNPs $a$ included in the prediction model for tissue $l$, with $w_{a}^{l}$ as the weight of SNP $a$ in this model, and $X_a$ as the genotype of SNP $a$.
The transformation to $\

S-PrediXcan [@doi:10.1038/s41467-018-03621-1] serves as a streamlined version of PrediXcan [@doi:10.1038/ng.3367], which conceptualizes the relationship between a trait and gene expression in a specific tissue through a univariate model described by the equation

$$
\mathbf{y} = \mathbf{t}_l \gamma_l + \bm{\epsilon}_l,
$$ {#eq:predixcan}

where $\gamma_l$ represents the estimated effect size or regression coefficient, and $\bm{\epsilon}_l$ denotes the error terms, which have a variance denoted by $\sigma_{\epsilon}^{2}$.
The significance of any gene-tissue association is determined by calculating the $z$-score, $\hat{z}_{l}=\hat{\gamma}_l / \mathrm{se}(\hat{\gamma}_l)$, for each gene's model in tissue $l$.
The original PrediXcan framework requires individual-level data to establish this model.
Conversely, S-PrediXcan is designed to estimate PrediXcan's $z$-scores utilizing solely GWAS summary statistics through the formula

$$
\hat{z}_{l} \approx \sum_{a \in model_{l}} w_a^l \frac{\hat{\sigma}_a}{\hat{\sigma}_l} \frac{\hat{\beta}_a}{\mathrm{se}(\hat{\beta}_a)},
$$ {#eq:spredixcan}

where $\hat{\sigma}_a$ signifies the variance of SNP $a$, $\hat{\sigma}_l$ is the variance of the predicted gene expression in tissue $l$, and $\hat{\beta}_a$ is the estimated effect size of SNP $a$ according to the GWAS.
The estimation of genotype variances and covariances in these Transcriptome-Wide Association Study (TWAS) methods consistently relies on data from the Genotype-Tissue Expression project (GTEx v8) [@doi:10.1126/science.aaz1776] as a reference panel.
S-PrediXcan's capacity to indicate the direction of effects for specific tissues (e.g., whether higher or lower predicted gene expression is associated with increased or decreased disease risk) is leveraged in our methodology for drug repurposing, as further detailed in the subsequent sections.

S-MultiXcan, as described by Barbeira et al.
(2019), represents a streamlined version of MultiXcan, which itself is an advancement over PrediXcan with enhanced capability to detect gene-trait associations, albeit without indicating the direction of these effects.
The primary output of S-MultiXcan is the $p$-value, derived from an F-test, of its multiple tissue model, formalized as

$$
\begin{split}
\mathbf{y} & = \sum_{l=1}^{p} \mathbf{t}_l g_l + \mathbf{e} \\
& = \mathbf{T} \mathbf{g} + \mathbf{e},
\end{split}
$$ {#eq:multixcan}

where $\mathbf{T}$ denotes a matrix consisting of $p$ columns $\mathbf{t}_l$, each representing the predicted gene expression in tissue $l$.
Here, $\hat{g}_l$ symbolizes the estimated effect size for the predicted gene expression in tissue $l$, making $\hat{\mathbf{g}}$ a vector comprising $p$ estimated effect sizes $\hat{g}_l$.
The term $\mathbf{e}$ represents the error terms, characterized by a variance denoted by $\sigma_{e}^{2}$.
To mitigate collinearity issues stemming from the high correlation among predicted expression values of a gene across different tissues, MultiXcan employs the principal components (PCs) of $\mathbf{T}$.
The joint regression estimates, including effect sizes and their variances as delineated in Equation (@eq:multixcan), are derived by S-MultiXcan using the marginal estimates from S-PrediXcan, as specified in Equation (@eq:spredixcan).
Under the assumption of no association (the null hypothesis), the formula $\hat{\mathbf{g}}^{\top} \frac{\mathbf{T}^{\top}\mathbf{T}}{\sigma_{e}^{2}} \hat{\mathbf{g}}$ follows a $\chi_{p}^{2}$ distribution, enabling the assessment of association significance in S-MultiXcan through

$$
\begin{split}
\frac{\hat{\mathbf{g}}^{\top} (\mathbf{T}^{\top}\mathbf{T}) \hat{\mathbf{g}}}{\sigma_{e}^{2}} & \approx \bm{\hat{\gamma}}^{\top} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \left(\frac{\mathbf{T}^{\top} \mathbf{T}}{n-1}\right)^{-1} \frac{\sqrt{n-1}}{\sigma_{\epsilon}} \bm{\hat{\gamma}} \\
& = \hat{\mathbf{z}}^{\top} Cor(\mathbf{T})^{-1} \hat{\mathbf{z}},
\end{split}
$$ {#eq:smultixcan}

where $\hat{\mathbf{z}}$ consists of $p$ $z$-scores for each tissue available for the gene, as derived from Equation (@eq:spredixcan), and $Cor(\mathbf{T})$ represents the autocorrelation matrix of $\mathbf{T}$.
Given the singularity of $\mathbf{T}^{\top}\mathbf{T}$ for numerous genes, S-MultiXcan computes the pseudo-inverse $Cor(\mathbf{T})^{+}$ employing the top $k$ PCs, thereby approximating $\hat{\mathbf{z}}^{\top} Cor(\mathbf{T})^{+} \hat{\mathbf{z}}$ to follow a $\chi_k^2$ distribution.
This approach is predicated on a conservative approximation, $\sigma_{e}^{2} \approx \sigma_{\epsilon}^{2}$, implying that the variance of the error terms in the joint regression closely approximates the residual variance from the marginal regressions.
Notably, while $Cor(\mathbf{T})$ is estimated using a global genotype covariance matrix, the marginal $\hat{z}_l$ values in Equation (@eq:spredixcan) are derived using tissue-specific genotype covariances.
Despite S-MultiXcan producing highly concordant estimates in comparison to MultiXcan, it is important to acknowledge that results across genes are not perfectly correlated, as highlighted by Barbeira et al.
(2019).
These distinctions play a crucial role in our LV-based regression model, particularly in the computation of the gene-gene correlation matrix.
We incorporated results from S-MultiXcan in our LV-based regression model and in our cluster analyses of traits, leveraging its robust methodology to illuminate the complex interplay between genetic associations, gene expression patterns, and their implications for disease etiology and drug mechanisms.


### TWAS resources {#sec:methods:twas}

We used two large TWAS resources from different cohorts for discovery and replication, all obtained from European ancestries.
PhenomeXcan [@doi:10.1126/sciadv.aba2083], our discovery cohort, provides results on 4,091 traits across different categories.
Supplementary Data 1 has all the details about the included GWAS, sample size and disease/trait categories.
In PhenomeXcan, these publicly available GWAS summary statistics were used to compute
1) gene-based associations with the PrediXcan family of methods (described before), and
2) a posterior probability of colocalization between GWAS loci and *cis*-eQTL with fastENLOC [@doi:10.1126/sciadv.aba2083; @doi:10.1016/j.ajhg.2020.11.012].
We refer to the matrix of $z$-scores from S-PrediXcan (Equation (@eq:spredixcan)) across $q$ traits and $m$ genes in tissue $t$ as $\mathbf{M}^{t} \in \mathbb{R}^{q \times m}$.
As explained later, matrices $\mathbf{M}^{t}$ were used in our LV-based drug repurposing framework since they provide direction of effects.
The S-MultiXcan results (22,515 gene associations across 4,091 traits) were used in our LV-based regression framework and our cluster analyses of traits.
For the cluster analyses, we used the $p$-values converted to $z$-scores: $\mathbf{M}=\Phi^{-1}(1 - p/2)$, where $\Phi^{-1}$ is the probit function.
Higher $z$-scores correspond to stronger associations.

Our discovery cohort was eMERGE [@doi:10.1038/gim.2013.72], where the same TWAS methods were run on 309 phecodes [@doi:10.1101/2021.10.21.21265225] across different categories (more information about traits are available in [@doi:10.1101/2021.10.21.21265225]).
We used these results to replicate the associations found with our LV-based regression framework in PhenomeXcan.


### MultiPLIER and Pathway-level information extractor (PLIER) {#sec:methods:multiplier}

The MultiPLIER methodology [@doi:10.1016/j.cels.2019.04.003] leverages the recount2 dataset [@doi:10.1038/nbt.3838], excluding GTEx samples, to identify patterns of gene co-expression.
This process employs the PLIER (Pathway-Level Information Extractor) algorithm [@doi:10.1038/s41592-019-0456-1], which is designed for unsupervised learning that incorporates prior biological knowledge, specifically canonical pathways, to mitigate technical variability inherent in the data.
PLIER achieves this by employing a matrix factorization technique to decompose gene expression data into a series of latent variables (LVs).
Each LV corresponds to a gene module, encapsulating a specific pattern of gene expression that can be linked to biological pathways.
Through the application of MultiPLIER, the dimensionality of the recount2 dataset was effectively reduced to 987 LVs.

The matrix factorization method at the core of PLIER can be summarized by the following equation:

$$
X = ZY + E
$$

where \(X\) represents the original gene expression data matrix, \(Z\) is the matrix of latent variables (LVs), \(Y\) is the coefficient matrix linking LVs to the original gene expression features, and \(E\) denotes the residual matrix capturing the portion of gene expression not explained by the model.
In this context, each column of \(Z\) represents a different LV, and each LV is associated with a specific pattern of gene co-expression that can be interpreted in the context of known

In our analysis, we utilize a gene expression dataset, denoted as $\mathbf{Y}^{m \times c}$, which comprises expressions of $m$ genes across $c$ experimental conditions.
Additionally, we incorporate a prior knowledge matrix, $\mathbf{C} \in \{0,1\}^{m \times p}$, derived from $p$ MSigDB pathways [@doi:10.1016/j.cels.2015.12.004], where $\mathbf{C}_{ij} = 1$ indicates the membership of gene $i$ in pathway $j$.
To elucidate the underlying biological patterns and associations, we employ the PLIER method, which seeks to identify matrices $\mathbf{U}$, $\mathbf{Z}$, and $\mathbf{B}$ that minimize the following objective function:

$$
||\mathbf{Y} - \mathbf{Z}\mathbf{B}||^{2}_{F} + \lambda_1 ||\mathbf{Z} - \mathbf{C}\mathbf{U}||^{2}_{F} + \lambda_2 ||\mathbf{B}||^{2}_{F} + \lambda_3 ||\mathbf{U}||_{L^1}
$$ {#eq:met:plier_func}

Here, the constraint $\mathbf{U}>0, \mathbf{Z}>0$ ensures that the matrices are positive.
The matrix $\mathbf{Z}^{m \times l}$, containing gene loadings, maps the genes to $l$ latent variables (LVs), while $\mathbf{B}^{l \times c}$ represents the latent space corresponding to the $c$ conditions.
The matrix $\mathbf{U}^{p \times l}$ indicates the association of the $p$ pathways in $\mathbf{C}$ with each LV.
The regularization parameters $\lambda_i$ are applied to control the model's complexity and to prevent overfitting during the optimization process.
The matrix $\mathbf{Z}$ serves as a low-dimensional representation of the gene space, where each LV is intended to align as closely as possible with prior knowledge.
This alignment may reveal known or novel gene modules, representing significant biological patterns, or it may capture noise, depending on the data and the specificity of the prior knowledge utilized.

For our analyses aimed at drug repurposing and clustering of complex traits, we employed a model to map associations between genes and traits (derived from Transcriptome-Wide Association Studies, TWAS) as well as gene-drug associations (sourced from the Library of Integrated Network-based Cellular Signatures, LINCS L1000 dataset) into a reduced-dimensional space defined by gene modules.
Specifically, associations from TWAS, denoted by $\mathbf{M}$ (which could originate from either S-PrediXcan or S-MultiXcan methodologies), were mapped using the equation:

$$
\hat{\mathbf{M}} = (\mathbf{Z}^{\top} \mathbf{Z} + \lambda_{2} \mathbf{I})^{-1} \mathbf{Z}^{\top} \mathbf{M},
$$ {#eq:proj}

in this equation, $\hat{\mathbf{M}}^{l \times q}$ represents a matrix in which traits are associated with gene modules rather than individual genes, thereby providing a more integrative view of gene-trait associations.
Here, $\mathbf{Z}^{\top}$ denotes the transpose of the matrix $\mathbf{Z}$, which encapsulates the gene-module relationships, $\lambda_{2}$ is a regularization parameter that helps to mitigate overfitting by penalizing the magnitude of the coefficients, and $\mathbf{I}$ is the identity matrix.
This projection technique was analogously applied to project the drug-induced transcriptional profiles obtained from the LINCS L1000 dataset, thus enabling the representation of drugs in terms of gene modules.
This approach facilitates the identification of potential therapeutic targets and offers insights into the mechanisms of drugs, thereby


### Regression model for LV-trait associations {#sec:methods:reg}

We adapted the gene-set analysis framework from MAGMA [@doi:10.1371/journal.pcbi.1004219] to TWAS.
We used a competitive test to predict gene-trait associations from TWAS using gene weights from an LV, testing whether top-weighted genes for an LV are more strongly associated with the phenotype than other genes with relatively small or zero weights.
Thus, we fit the model

$$
\mathbf{m}=\beta_{0} + \mathbf{s} \beta_{s} + \sum_{i} \mathbf{x}_{i} \beta_{i} + \bm{\epsilon},
$$ {#eq:reg:model}

In the methods section of our study titled 'Projecting genetic associations through gene expression patterns highlights disease etiology and drug mechanisms', we employed a rigorous approach to analyze genetic studies, leveraging functional genomics to elucidate the clustering of complex traits and identify potential therapeutic targets and opportunities for drug repurposing.
Our analysis hinges on the integration of gene co-expression patterns and genetic association data to uncover the underlying mechanisms of disease etiology and the functional impact of genetic variants.

Central to our methodology is the construction of a vector $\mathbf{m}$, which represents the S-MultiXcan gene $p$-values associated with a specific trait.
These $p$-values undergo a $-log_{10}$ transformation to facilitate further analysis.
Additionally, we define $\mathbf{s}$ as a binary indicator vector, where $s_{\ell}=1$ for genes that fall within the top 1% based on their loadings for latent variable (LV) $\ell$ extracted from $\mathbf{Z}_{\ell}$, and zero otherwise.
This selection criterion is pivotal for identifying genes with significant contributions to the trait of interest.

Furthermore, the model incorporates $\mathbf{x}_{i}$, a gene property vector that serves as a covariate in our analysis.
This allows for the adjustment of gene-specific effects that could confound the relationship between gene expression patterns and trait associations.

The effect sizes, denoted by $\beta$, with $\beta_{0}$

In our analytical model, we evaluate the null hypothesis, denoted as $\beta_{s} = 0$, against the alternative hypothesis that suggests a positive association, $\beta_{s} > 0$.
Here, the parameter $\beta_{s}$ is intended to capture the differential association of traits with genes that are constituents of Latent Variable (LV) $\ell$, in comparison to genes that are not included within this LV.
This approach is in alignment with the methodology established by the MAGMA framework.
To facilitate this analysis, we incorporated two specific gene characteristics as covariates into our model.
The first covariate is *gene size*, which we operationalize as the number of Principal Components (PCs) retained following the application of S-MultiXcan.
The second covariate, *gene density*, is quantified as the ratio of the number of PCs to the total number of tissues examined.
These covariates are crucial for adjusting our model to account for inherent gene characteristics that could influence the observed genetic associations.

$$
\beta_{s} = 0
$$

and

$$
\beta_{s} > 0
$$

In these equations, $\

To account for the potential correlation between error terms $\bm{\epsilon}$, which may not follow independent normal distributions as typically assumed in a standard linear regression model, we utilized a generalized least squares approach.
This decision was informed by the understanding that the predicted expression of a gene pair could be correlated due to shared eQTLs or linkage disequilibrium (LD) as discussed in the context of the PrediXcan family of methods [@doi:10.1038/s41588-019-0385-z].
To address this, we estimated the gene-gene correlation matrix $\mathbf{R}$ by computing correlations between the model sum of squares (SSM) for each gene pair, assuming no association.
These correlations are based on the individual-level MultiXcan model (Equation (@eq:multixcan)), where the predicted expression matrix $\mathbf{T}_{i} \in \mathbb{R}^{n \times p_i}$ for gene $i$ across $p_i$ tissues is projected onto its top $k_i$ principal components (PCs), resulting in a matrix $\mathbf{P}_{i} \in \mathbb{R}^{n \times k_i}$.
According to the MAGMA framework, the SSM for each gene is proportional to $\mathbf{y}^{\top} \mathbf{P}_{i} \mathbf{P}_{i}^{\top} \mathbf{y}$.
Under the null hypothesis of no association, the covariance between the SSMs of genes $i$ and $j$ is therefore $2 \times \mathrm{Trace}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})$, with the standard deviations of each SSM given by $\sqrt{2 \times k_{i}} \times (n - 1)$.
The correlation between the SSMs for genes $i$ and $j$ can be expressed as:

$$
\begin{split}
\mathbf{R}_{ij} & = \frac{2 \times \mathrm{Tr}(\mathbf{P}_{i}^{\top} \mathbf{P}_{j} \mathbf{P}_{j}^{\top} \mathbf{P}_{i})}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}} \times (n - 1)^2} \\
& = \frac{2 \times \mathrm{Tr}(Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \times Cor(\mathbf{P}_{j}, \mathbf{P}_{i}))}{\sqrt{2 \times k_{i}} \times \sqrt{2 \times k_{j}}},
\end{split}
$$ {#eq:reg:r}

where $\mathrm{Tr}$ denotes the trace of a matrix, and the columns of $\mathbf{P}$ are standardized.
The cross-correlation matrix between PCs, $Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) \in \mathbb{R}^{k_i \times k_j}$, is defined by

$$
\begin{split}
Cor(\mathbf{P}_{i}, \mathbf{P}_{j}) & = Cor(\mathbf{T}_{i} \mathbf{V}_{i}^{\top} \mathrm{diag}(\lambda_i)^{-1/2}, \mathbf{T}_{j} \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2}) \\
& = \mathrm{diag}(\lambda_i)^{-1/2} \mathbf{V}_{i} (\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1}) \mathbf{V}_{j}^{\top} \mathrm{diag}(\lambda_j)^{-1/2},
\end{split}
$$ {#eq:reg:cor_pp}

where $\mathbf{V}_{i}$ and $\lambda_i$ represent the eigenvectors and eigenvalues of $\mathbf{T}_{i}$, respectively, and $\frac{\mathbf{T}_{i}^{\top} \mathbf{T}_{j}}{n-1} \in \mathbb{R}^{p_i \times p_j}$ is the cross-correlation matrix between the predicted expression levels of genes $i$ and $j$.
To estimate the correlation of predicted expression levels for genes $i$ in tissue $k$ and gene $j$ in tissue $l$, we utilized the approach outlined in [@doi:10.1371/journal.pgen.1007889]:

$$
\begin{split}
\frac{(\mathbf{T}_{i}^{\top} \mathbf{T}_{j})_{kl}}{n-1} & = Cor(\mathbf{t}_k^i, \mathbf{t}_l^j) \\
& = \frac{ Cov(\mathbf{t}_k, \mathbf{t}_l) } { \sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
& = \frac{ Cov(\sum_{a \in \mathrm{model}_k} w_a^k X_a, \sum_{b \in \mathrm{model}_l} w_b^l X_b) }  {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
& = \frac{ \sum_{\substack{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l}} w_a^k w_b^l Cov(X_a, X_b)} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} } \\
& = \frac{ \sum_{\substack{a \in \mathrm{model}_k \\ b \in \mathrm{model}_l}} w_a^k w_b^l \Gamma_{ab}} {\sqrt{\widehat{\mathrm{var}}(\mathbf{t}_k) \widehat{\mathrm{var}}(\mathbf{t}_l)} },
\end{split}
$$ {#eq:reg:corr_genes}

where $X_a$ denotes the genotype of SNP $a$, $w_a^k$ and $w_b^l$ are the weights of SNP $a$ and $b$ for gene expression prediction in tissue models $k$ and $l$, respectively, and $\Gamma = \widehat{\mathrm{var}}(\mathbf{X})$ is the genotype covariance matrix, calculated using GTEx v8 as the reference panel.
The variance of the predicted expression values for gene $i$ in tissue $k$ is derived as follows:

$$
\begin{split}
\widehat{\mathrm{var}}(\mathbf{t}_k^i) & = (\mathbf{W}^k)^\top \Gamma^k \mathbf{W}^k \\
& = \sum_{\substack{a \in \mathrm{model}_k \\ b \in \mathrm{model}_k}} w_a^k w_b^k \Gamma_{ab}^k.
\end{split}
$$ {#eq:reg:var_gene}

In our study, we employed the MultiXcan regression model, as outlined in Equation (@eq:multixcan).
It is important to note that within this framework, $\mathbf{R}$ serves as an approximation for gene correlations in the context of S-MultiXcan.
The methodology behind S-MultiXcan involves approximating the joint regression parameters found in MultiXcan by utilizing marginal regression estimates derived from S-PrediXcan, as presented in Equation (@eq:spredixcan).
This process incorporates simplifying assumptions alongside varying genotype covariance matrices, thereby complicating the derivation of an S-MultiXcan-specific method for calculating $\mathbf{R}$.
To navigate this complexity, we opted to use a submatrix, $\mathbf{R}_{\ell}$, which only includes genes from latent variable (LV) $\ell$ (specifically, the top 1% of genes), rather than leveraging the full matrix $\mathbf{R}$.
This approach is considered conservative due to its focus on correlations among the top genes exclusively.

$$
\mathbf{R}_{\ell} = \text{Covariance matrix for top 1% genes in LV} \ell
$$

{#eq:Rl}

Our simulations, as detailed in [Supplementary Note 1](#sm:reg:null_sim), demonstrate that the model maintains approximate calibration and is capable of correcting for LVs characterized by adjacent and highly correlated top genes (see, for example, Figure @fig:reg:nulls:qqplot:lv234).
However, these simulations also revealed that 127 LVs did not exhibit proper calibration within the model framework (as illustrated in Figure @fig:reg:nulls:qqplot:lv914).
We attribute this discrepancy to challenges in accurately computing the gene correlation matrix.
Consequently, these LVs were excluded from our primary analyses to ensure the integrity of our findings.

To estimate gene expression correlations accurately, we adhered to a specific approach as outlined in Equation (@eq:reg:corr_genes).
This equation was applied only to tissue models that are included in the S-PrediXcan results and to single nucleotide polymorphisms (SNPs) that were used in the genome-wide association studies (GWAS) for transcriptome-wide association studies (TWAS) methods.
This strategy is crucial for deriving precise correlation estimates, as highlighted by previous research [@doi:10.1371/journal.pgen.1007889].
Consequently, we generated distinct correlation matrices tailored for PhenomeXcan and eMERGE datasets to reflect their unique characteristics.

$$
\text{Correlation Equation} = \frac{\sum (X - \bar{X})(Y - \bar{Y})}{\sqrt{\sum (X - \bar{X})^2(Y - \bar{Y})^2}}
$$ {#eq:reg:corr_genes}

In this equation, \(X\) and \(Y\) represent the expression levels of two different genes, while \(\bar{X}\) and \(\bar{Y}\) denote the average expression levels of these genes, respectively. 

For the PhenomeXcan data, the majority of GWAS (4,049 in total) were sourced from the UK Biobank, utilizing a uniform pipeline and incorporating an identical set of SNPs.
Thus, a single correlation matrix was deemed sufficient for these analyses.
Conversely, for traits that did not originate from the UK Biobank or that involved a different array of SNPs, we opted for a tailored approach by computing

We ran our regression model for all 987 LVs across the 4,091 traits in PhenomeXcan.
For replication, we ran the model in the 309 phecodes in eMERGE.
We adjusted the $p$-values using the Benjamini-Hochberg procedure.


### LV-based drug repurposing approach {#sec:methods:drug}

For the drug-disease prediction, we employed an LV-based method inspired by a drug repositioning framework previously utilized for psychiatric traits [@doi:10.1038/nn.4618].
This framework focuses on identifying anticorrelations between the expression profiles of individual genes associated with a trait and those altered by drugs.
We evaluated the performance of our LV-based approach in comparison to this established single-gene method.
In implementing the single-gene strategy, we calculated a drug-disease score by multiplying a set of signed $z$-scores, $\mathbf{M}^t$, derived from S-PrediXcan for tissue $t$, with another set of signed $z$-scores, $\mathbf{L}^{c \times m}$, representing transcriptional responses to $c$ compounds as profiled in the LINCS L1000 dataset [@doi:10.1016/j.cell.2017.10.049].
The matrix $\mathbf{M}^t$ encapsulates whether an increased or decreased predicted expression of a gene is implicated in disease risk, while $\mathbf{L}$ indicates whether a drug is associated with an increase or decrease in gene expression.
Multiplying these matrices yields a score for each drug-disease pair, as expressed by the equation:

$$
\mathbf{D}^{t,k}=-1 \cdot \mathbf{M}^{t,k} \mathbf{L}^\top
$$

Here, $k$ denotes the number of most significant gene associations within $\mathbf{M}^t$ for each trait.
Following the approach suggested in [@doi:10.1038/nn.4618], we considered various thresholds for $k$, including all genes or the top 50, 100, 250, and 500 genes.
Subsequently, we averaged the score ranks across all values of $k$ to compute $\mathbf{D}^t$.
To determine the strongest prediction for each drug-disease pair, we selected the highest prediction score across all tissues, represented by:

$$
\mathbf{D}_{ij} = \max \{ \mathbf{D}_{ij}^t \mid \forall t \}
$$

In these equations, $\mathbf{D}^{t,k}$ represents the drug-disease score for tissue $t$ and the $k$ most significant gene associations, $\mathbf{M}^{t,k}$ denotes the matrix of signed $z$-scores for gene associations in tissue $t$, and $\mathbf{L}^\top$ signifies the transpose of the matrix of signed $z$-scores for transcriptional responses to drugs.
$\mathbf{D}_{ij}$ is the maximum prediction score for the drug-disease pair indexed by $i$ and $j$.


For the latent variable (LV)-based approach, we employed a similar methodology, where the trait-associated gene expression matrix $\mathbf{M}^{t}$ and the gene co-expression matrix $\mathbf{L}$ were projected into the gene module latent space.
This projection was performed in accordance with Equation (@eq:proj), resulting in the transformed matrices $\hat{\mathbf{M}}^t$ and $\hat{\mathbf{L}}^{l \times c}$, respectively.
Subsequently, the distance matrix $\mathbf{D}^{t,k}$ was calculated as $\mathbf{D}^{t,k}=-1 \cdot \hat{\mathbf{L}}^{\top} \hat{\mathbf{M}}^{t,k}$, where $k$ represents either all latent variables (LVs) or a subset thereof, specifically the top 5, 10, 25, or 50 LVs.
This selection process was necessitated due to the significantly lower number of LVs compared to genes. 

$$
\mathbf{D}^{t,k}=-1 \cdot \hat


Since the gold standard of drug-disease medical indications is described with Disease Ontology IDs (DOID) [@doi:10.1093/nar/gky1032], we mapped PhenomeXcan traits to the Experimental Factor Ontology [@doi:10.1093/bioinformatics/btq099] using [@url:https://github.com/EBISPOT/EFO-UKB-mappings], and then to DOID.


### Consensus clustering of traits {#sec:methods:clustering}

In the preprocessing phase of the S-MultiXcan results, prior to conducting the cluster analysis, we executed two crucial steps.
Initially, for those traits that were associated with the same Experimental Factor Ontology (EFO) term, we aggregated the results within the matrix $\mathbf{M}$, transforming $p$-values into $z$-scores as previously outlined.
This aggregation was accomplished through the application of Stouffer's method, expressed mathematically as:

$$
\frac{\sum w_i M_{ij}}{\sqrt{\sum w_i^2}}
$$ {#eq:stouffer}

In this equation, $w_i$ represents a weight assigned based on the GWAS sample size for trait $i$, and $M_{ij}$ denotes the $z$-score corresponding to gene $j$.
This method facilitates the integration of results across traits mapped to identical EFO terms [@doi:10.1093/bioinformatics/btq099].

Subsequently, to mitigate the influence of traits characterized by a high degree of polygenicity, we normalized the $z$-scores for each trait $i$.
This was achieved by dividing each $z$-score, $M_{ij}$, by the sum of all $z$-scores for that trait:

$$
\frac{M_{ij}}{\sum M_{ij}}
$$ {#eq:normalization}

Upon completing these preprocessing steps, we proceeded to project the refined data matrix using Equation (@eq:proj).
This projection yielded a transformed matrix, $\hat{\mathbf{M}}$, which comprised $n$=3,752 traits and $l$=987 latent variables (LVs).
This matrix served as the input for our subsequent clustering analysis, enabling us to explore the underlying structure within the data.


A partitioning of the estimated matrix $\hat{\mathbf{M}}$, which contains $n$ traits, into $k$ clusters is denoted by a label vector $\pi \in \mathbb{N}^n$.
The process of consensus clustering is conducted in two primary steps: 1) the creation of an ensemble $\Pi$ comprising $r$ different partitions of the dataset, represented as $\Pi=\{\pi_1, \pi_2, \ldots, \pi_r\}$, and 2) the amalgamation of this ensemble into a unified solution, which is mathematically defined as:

$$
\pi^* = \mathrm{arg}\,\underset{\hat{\pi}}{\max} Q(\{ \lvert \mathcal{L}^i \lvert \phi(\hat{\pi}_{\mathcal{L}^i}, \pi_{i \mathcal{L}^i}) \mid i \in \{1,\ldots,r\} \}),
$$ {#eq:consensus:obj_func}

In this equation, $\mathcal{L}^i$ denotes the set of data indices that possess known cluster labels for the $i$th partition, $\phi\colon \mathbb{N}^n \times \mathbb{N}^n \to \mathbb{R}$ is a similarity measurement function between two partitions, and $Q$ represents a measure of central tendency, such as the mean or median.
The adjusted Rand index (ARI) [@doi:10.1007/BF01908075] was selected as the function for $\phi$, and the median was chosen for $Q$.
To derive $\pi^*$, a consensus function $\Gamma\colon \mathbb{N}^{n \times r} \to \mathbb{N}^n$ is defined with $\Pi$ serving as its input.
This approach is grounded in the evidence accumulation clustering (EAC) paradigm [@doi:10.1109/TPAMI.2005.113], wherein $\Pi$ is initially converted into a co-occurrence matrix $\mathbf{D}_{ij} = d_{ij} / r$, with $d_{ij}$ signifying the count of instances where traits $i$ and $j$ were positioned in differing clusters across all $r$ partitions in $\Pi$.
Subsequently, $\Gamma$ employs any similarity-based clustering algorithm on $\mathbf{D}$ to generate the ultimate partition $\pi^*$.


In the ensemble generation phase of our study, we employed a variety of algorithms to generate a highly diverse collection of partitions, as illustrated in Figure @fig:clustering:design.
The importance of diversity in ensemble methods is well-documented in the literature [@doi:10.1016/j.ins.2016.04.027; @doi:10.1109/TPAMI.2011.84; @doi:10.1016/j.patcog.2014.04.005].
Our approach utilized three distinct data representations: the original dataset, a projection into the top 50 principal components, and an embedding generated by UMAP [@arxiv:1802.03426] with 50 components.
To these representations, we applied five clustering algorithms, each based on different assumptions about the structure of the data: $k$-means [@Arthur2007], spectral clustering [@Ng2001], Gaussian mixture models (GMM), hierarchical clustering, and DBSCAN [@Ester1996].
For $k$-means, spectral clustering, and GMM, we selected a range of cluster numbers $k$ from 2 to $\sqrt{n} \approx 60$, producing five partitions for each $k$ value using different random seeds.
In hierarchical clustering, we generated four partitions for each $k$ value, employing common linkage criteria: ward, complete, average, and single.
For DBSCAN, we explored a range of values for $\epsilon$ (the maximum distance between two data points for them to be considered part of the same neighborhood) and *minPts* (the minimum number of data points required in a neighborhood for a point to be classified as a core point), following the methodology outlined in [@doi:10.1088/1755-1315/31/1/012012].
We set *minPts* to vary from 2 to 125.
To determine a plausible range of $\epsilon$ values for each data representation (raw, PCA, and UMAP), we examined the distribution of the mean distance to the *minPts*-nearest neighbors across all data points.
Given that certain parameter combinations for *minPts* and $\epsilon$ might not yield meaningful partitions (e.g., when all points are labeled as noise or a single cluster is identified), we adjusted the sampling of partitions produced by DBSCAN to ensure balanced representation of this algorithm in the ensemble.
This approach resulted in a comprehensive ensemble comprising 4,428 partitions across 3,752 traits.


Finally, we employed spectral clustering on the distance matrix $\mathbf{D}$ to obtain the final consensus partitions.
The process began by transforming $\mathbf{D}$ into a similarity matrix, accomplished through the application of an RBF kernel, defined as $\mathrm{exp}(-\gamma \mathbf{D}^2)$.
This transformation utilized four distinct values for the parameter $\gamma$, which were determined empirically to yield optimal results.

$$
\mathrm{exp}(-\gamma \mathbf{D}^2) {#eq:rbf_kernel}
$$

In the equation above, $\gamma$ represents the parameter of the RBF kernel, adjusting the width of the Gaussian function, and $\mathbf{D}^2$ symbolizes the squared distance matrix.

Subsequently, for each potential number of clusters $k$ ranging from 2 to 60, we generated four consensus partitions corresponding to the different $\gamma$ values.
Among these, we selected the partition that achieved the highest score according to the consensus objective function, denoted as Equation (@eq:consensus:obj_func).

$$
\text{Consensus Objective Function} {#eq:consensus:obj_func}
$$

The collection of 59 solutions obtained was then refined by retaining only those with an ensemble agreement exceeding the 75th percentile, as depicted in Figure @fig:sup:clustering:agreement.
This filtering process resulted in a final set of 15 consensus partitions, which are illustrated in Figure @fig:clustering:tree.
This methodological approach ensures that the selected partitions exhibit a significant level of agreement among the various $\gamma$ configurations, thereby enhancing the reliability and interpretability of the clustering outcomes.

In our clustering pipeline, the input data is subject to a series of transformations, both linear and nonlinear, which include Principal Component Analysis (PCA), Uniform Manifold Approximation and Projection (UMAP), and an ensemble transformation employing the Evidence Accumulation Clustering (EAC) paradigm to construct the distance matrix $\mathbf{D}$.
Despite the recognized benefits of consensus clustering for analyzing biological datasets [@pmid:27303057], these transformations introduce complexities in interpreting the outcomes.
To address this challenge, we adopted a supervised learning strategy aimed at identifying the gene modules or latent variables (LVs) that are most indicative of each trait cluster, as depicted in Figure {@fig:clustering:design}b.
It is important to note that our use of the supervised model was not for predictive purposes but rather to ascertain the features (LVs) that were most distinctive for each cluster.
We selected the partition with the highest resolution ($k=29$, although any resolution could be applied) as the basis for training a decision tree model, using the clusters as labels and the projected data $\hat{\mathbf{M}}$ as the input.
For each value of $k$, we generated a set of binary labels, designating the traits within the current cluster as the positive class and all other traits as the negative class.
The LV at the root node of the decision tree was selected only if its threshold was positive and exceeded one standard deviation.
This LV was then removed from $\hat{\mathbf{M}}$, irrespective of whether it had been selected, and the model was retrained.
This process was iterated 20 times to identify the top 20 LVs that most effectively differentiate the traits within a cluster from those outside it.

$$
\mathbf{D} = \text{distance matrix derived from EAC}
$$

$$
\hat{\mathbf{M}} = \text{projected data used as training samples}
$$

Here, $\mathbf{D}$ represents the distance matrix obtained through the EAC paradigm, encapsulating the dissimilarities between data points based on their co-association across multiple clustering results.
The projected data $\hat{\mathbf{M}}$ serves as the training samples for the supervised learning model, encapsulating the essential features of the input data post-transformation.

In [Supplementary Note 2](#sm:clustering:null_sim), we performed several analyses under a null hypothesis of no structure in the data to verify that the clustering results detected by this pipeline were real.


### CRISPR-Cas9 screening {#sec:methods:crispr}

**Cell culture.** HepG2 cells, obtained from ATCC (ATCC® HB-8065™), were cultured in Eagle's Minimum Essential Medium with L-Glutamine (EMEM, Cat.
112-018-101, Quality Biology), which was supplemented with 10% Fetal Bovine Serum (FBS, Gibco, Cat.16000-044), and 1% Pen/Strep (Gibco, Cat.15140-122).
The cells were incubated at 37°C in a humidity-controlled environment with a 5% CO2 atmosphere.
To maintain optimal growth conditions, the cells were not allowed to exceed 80% confluency and were grown in Collagen-I coated flasks.

**Genome-wide lentiviral pooled CRISPR-Cas9 library utilization.** The third-generation lentiviral Broad GPP genome-wide Human Brunello CRISPR knockout pooled library, kindly provided by David Root and John Doench from Addgene (Catalog No.
73179-LV), was employed for transduction of HepG2 cells.
This library encompasses 76,441 sgRNAs that collectively target 19,114 genes across the human genome, averaging approximately 4 sgRNAs per gene.
Each 20 nucleotide (nt) sgRNA cassette was integrated into the lentiCRISPRv2 vector, positioned between the U6 promoter and the gRNA scaffold.
For the purpose of cell transduction, lentiviral vectors bearing the Cas9 gene were utilized to introduce the sgRNA cassette-containing plasmids into the cells during the process of cell replication.
Cells that were not successfully transduced were subsequently eliminated via selection with puromycin.

**Lentiviral Titer Determination Methodology**

For the screening process, a no-spin lentiviral transduction approach was employed.
Cells, approximately 2.5 million, were seeded in each well of a Collagen-I coated 6-well plate, in conjunction with 8 µg/ml of polybrene (Millipore Sigma, Cat.
TR-1003 G).
Each well received a distinct volume of virus, specifically 0, 50, 100, 200, 250, and 400 µl, to establish a range for titration.
The wells were then filled with EMEM complete media to reach a final volume of 1.24 ml.
After a period of 16-18 hours post-transduction, the media containing the virus and polybrene was removed from each well.
This was followed by two washes with 1x DPBS, after which fresh EMEM media was added to the wells.
Subsequently, 24 hours post-transduction, the cells from each well were trypsinized, diluted (e.g., 1:10), and re-seeded into pairs of wells in 6-well plates.
At 60 hours post-transduction, the media in each well was replaced with fresh EMEM.
To one well of each pair, 2 µg/ml of puromycin (Gibco, Cat.
A1113803) was added.
After a period of 2-5 days following puromycin selection, or when no surviving cells were observed in the well with 0 virus treated with puromycin, cells from both wells (with and without puromycin) were collected and counted to assess viability.
The Percentage of Infection (PI%) was calculated by comparing the cell counts from wells with and without puromycin selection within each pair.

Utilizing Poisson's distribution theory, it is established that when the transduction efficiency (PI%) ranges between 30-50%, this corresponds to a Multiplicity of Infection (MOI) of approximately 0.35-0.70.
Specifically, at an MOI close to 0.3, it is estimated that about 25% of cells are infected, with the majority of these infected cells likely containing only a single copy of the virus.
Based on these calculations, a virus volume of 120 µl, which yields a transduction efficiency of 30-40%, was selected for subsequent large-scale viral transduction experiments.

This methodical approach ensures precision in determining the optimal virus volume for efficient transduction, pivotal for the success of the screening process in identifying relevant genetic associations and understanding disease etiology and drug mechanisms.

**Lentiviral Transduction in HepG2 Using Brunello CRISPR Knockout Pooled Library.** To ensure a coverage of at least 500 cells per single-guide RNA (sgRNA), and a multiplicity of infection (MOI) ranging from 0.3 to 0.4 to achieve a 95% probability that infected cells receive only a single viral particle, approximately 200 million cells were initiated for the screening process.
The transduction procedure was conducted following previously established protocols with minor modifications.
Specifically, 2.5 million cells were seeded into each well of fourteen 6-well plates, supplemented with 8 µg/ml of polybrene to enhance viral entry.
Subsequently, 120 µl of the lentiviral solution was dispensed into each experimental well.
At 18 hours post-transduction, the medium containing the virus and polybrene (virus/PB mix) was removed.
The cells from each well were then harvested, counted, and pooled together into T175 flasks for further cultivation. 

At 60 hours post-transduction, puromycin was added to each flask at a concentration of 2 µg/ml to select for successfully transduced cells.
The medium was refreshed every two days, maintaining the puromycin concentration at 2 µg/ml to ensure the elimination of non-transduced cells.
After a period of seven days under puromycin selection, the cells were again collected, pooled, counted, and re-seeded for subsequent experiments.
This methodological approach was designed to maximize the efficiency and accuracy of the CRISPR knockout screen by ensuring a high coverage of cells for each sgRNA and by employing a stringent selection process to isolate cells that have incorporated the viral particles.

**Fluorescent Dye Staining.** Nine days subsequent to the initiation of puromycin selection, the cells were categorized into two distinct groups.
A subset comprising 20-30 million cells was designated as the Unsorted Control.
This cell pellet was subjected to centrifugation at 500 x g for a duration of 5 minutes at a temperature of 4°C.
Subsequently, the pellet, devoid of any moisture, was preserved at -80°C to facilitate the extraction of genomic DNA at a later stage.
The remaining cell population, estimated to be around 200 million cells, was allocated to 100mm dishes and subjected to staining with a fluorescent dye, specifically LipidSpot™ 488 (Biotium, Catalog No.
70065-T).
In a concise procedure, the LipidSpot 488 dye was diluted to a 1:100 ratio using DPBS.
For each dish, 4ml of the staining solution was applied, followed by an incubation period at 37°C for 30 minutes.
The visualization of cells was accomplished through the employment of a fluorescent microscope, EVOS, designed for the detection of GFP signals (refer to Figure @fig:sup:crispr:fig1).

**Fluorescence-activated cell sorting (FACS).** Immediately following collection, cells were transferred into 50 ml tubes.
It is critical to maintain the cells at cold temperatures throughout the process.
The cells were centrifuged at 500 x g for 5 minutes at 4°C.
Subsequent to a DPBS wash, cell pellets were resuspended in FACS Sorting Buffer, which consists of 1x DPBS without Ca^2+/Mg^2+, 2.5 mM EDTA, 25 mM HEPES, and 1% BSA.
This solution was filter sterilized and stored at 4°C.
Resuspension was achieved through gentle pipetting to ensure the formation of single-cell suspensions.
The cell solution was then passed through a cell strainer (Falcon, Cat.
352235) and maintained on ice, shielded from light exposure. 

The sorting of collected cells was conducted on a FACSJazz instrument, utilizing a 100 µm nozzle.
Approximately 20% of each GFP-High and GFP-Low population (as depicted in Figure @fig:sup:crispr:fig2) were gathered into 15 ml tubes.
Immediately following the sorting process, the cells were centrifuged, and the resulting pellets were stored at -80°C for subsequent genomic DNA isolation. 

This methodology ensures the preservation of cell integrity and viability for downstream genetic analyses, crucial for understanding the genetic associations through gene expression patterns as highlighted in the study "Projecting genetic associations through gene expression patterns highlights disease etiology and drug mechanisms".
This approach is foundational in the exploration of functional genomics, therapeutic targets, and drug repurposing through the clustering of complex traits.

**Genomic DNA Isolation and Verification**

For the purpose of this study, genomic DNA (gDNA) was isolated from three distinct conditions: Un-Sorted Control, lentiV2 GFP-High, and lentiV2 GFP-Low.
The isolation process was carried out using the QIAamp DNA Blood Mini Kit (Qiagen, Cat.51104).
Following the extraction, the quality and quantity of the isolated gDNA were assessed through UV Spectroscopy using a Nanodrop device.
The quantity of gDNA isolated ranged between 80 to 160 µg for each condition.
To confirm the presence of the sgRNA cassette and the lentiviral specific transgene within the isolated gDNA, Polymerase Chain Reaction (PCR) was employed, with the results depicted in Figure @fig:sup:crispr:fig3.

**Illumina Libraries Generation and Sequencing**

To amplify the fragment containing the sgRNA cassette, we used P5/P7 primers following the procedure outlined in [@pmid:26780180], with primer sequences adapted from the Broad Institute protocol (Figure @fig:sup:crispr:table1).
The P5 included a stagger sequence (0-8 nucleotides), and the P7 primer contained an 8bp uniquely barcoded sequence.
We commissioned the synthesis of primers through Integrated DNA Technologies (IDT), ensuring each primer was PAGE purified for maximum quality.
For each experimental condition, we prepared 32 PCR reactions.
The composition of each 100μl PCR reaction was approximately 5μg of genomic DNA (gDNA) and 5μl of each 10μM P5 and P7 primer.
We utilized ExTaq DNA Polymerase (TaKaRa, Cat.
RR001A) for the amplification process.
The PCR conditions were set as follows: an initial denaturation at 95°C for 1 minute; this was followed by 24 cycles of denaturation at 94°C for 30 seconds, annealing at 52.5°C for 30 seconds, and extension at 72°C for 30 seconds.
A final elongation step was conducted at 72°C for 10 minutes.
We anticipated PCR products to range between 285bp and 293bp in size (Figure @fig:sup:crispr:fig4 A).
PCR products from the same condition were pooled together and then purified using SPRIselect beads (Beckman Coulter, Cat.
B23318).
The quantification of the purified Illumina libraries was performed using a Qubit fluorometer, and the library quality was assessed on a Bioanalyzer with a High Sensitivity DNA Chip.
We expected to observe a single peak around 285bp (Figure @fig:sup:crispr:fig4 B).
The final step involved sequencing the Illumina library samples on a NovaSeq 6000 system.
Samples were pooled and loaded onto an SP flow cell, to which a 20% PhiX control v3 library was added as a spike-in to ensure sequencing quality.


## Data availability

All the main datasets generated in this study are available at [https://doi.org/10.5281/zenodo.8071382](https://doi.org/10.5281/zenodo.8071382) [@doi:10.5281/zenodo.8071382] and the GitHub repository [https://github.com/greenelab/phenoplier](https://github.com/greenelab/phenoplier).

The main input datasets used are TWAS from PhenomeXcan [@doi:10.1126/sciadv.aba2083] for 4,091 traits and from the Electronic Medical Records and Genomics (eMERGE) network phase III [@doi:10.1101/2021.10.21.21265225] for 309 traits; transcriptional responses to small molecule perturbations from LINCS L1000 [@doi:10.1016/j.cell.2017.10.049] that were further preprocessed and mapped to DrugBank IDs from [@doi:10.5281/zenodo.47223]; latent space/gene module models from MultiPLIER [@doi:10.1016/j.cels.2019.04.003].

The datasets utilized in this study, sourced from PhenomeXcan, LINCS L1000, and MultiPLIER, are accessible to the public.
Detailed outcomes of the phenome-wide Transcriptome-Wide Association Studies (TWAS) conducted on the Electronic Medical Records and Genomics (eMERGE) network and the Penn Medicine BioBank (PMBB) cohorts, which are significant to our findings, are documented in the publication [@doi:10.1101/2021.10.21.21265225].
However, due to privacy concerns stipulated by institutional guidelines, the raw individual-level data from the PMBB cannot be disseminated publicly.
For those interested in accessing the PMBB dataset, requests can be directed to the Penn Medicine Biobank through their website ([https://pmbb.med.upenn.edu/pmbb/](https://pmbb.med.upenn.edu/pmbb/)).
Additionally, data from the third phase of the eMERGE network is publicly available and can be found on the database of Genotypes and Phenotypes (dbGAP) under the accession number phs001584.v2.p2.


## Code availability

The code necessary to reproduce all the analyses in this work is available at [https://doi.org/10.5281/zenodo.8071382](https://doi.org/10.5281/zenodo.8071382) [@doi:10.5281/zenodo.8071382] and the GitHub repository [https://github.com/greenelab/phenoplier](https://github.com/greenelab/phenoplier).

For the CRISPR screening, we utilized FlowJo v10.7 and FACS Jazz Software v1.1.
The data analysis was conducted using Python 3.8 and R 3.6, supplemented by a suite of computational packages.
Specifically, the primary Python packages employed were Jupyter Lab (2.2), pandas (1.1), matplotlib (3.3), seaborn (0.11), numpy (1.19), scipy (1.5), scikit-learn (0.23), and umap-learn (0.4).
On the R front, the key packages included Bioconductor (3.10), clusterProfiler (3.14), clustree (0.4), and fgsea (1.17).
In addition to utilizing these packages, we developed a series of scripts and notebooks, which have been made available under an open-source license.
Comprehensive documentation was prepared to detail every step required to replicate our analyses.
Furthermore, we have provided a Docker image to facilitate the use of the identical runtime environment that was employed in our study, along with a demo that enables users to quickly apply our methods to real data sets.
